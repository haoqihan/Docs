### 监督学习

监督学习的目标

- 利用一组带有标签的数据，学习从输入到输出的映射，然后将这种关系应用到未知数据上，达到分类或回归的目的
- 分类：当输出是离散的，学习任务为分类任务
- 回归：当输出是连续的，学习任务是回归任务

分类学习

- 输入：一组有标签的训练数据（也称观察和评估），标签表明了这些数据（观察）的所属类别
- 输出：分类模型根据这些训练数据，训练自己的模型参数，学习出一个适合这组数据的分类器，当有新数据（非训练数据）需要进行类别判断 ，就可以将这组新数据作为输入送给学习好的分类器进行判断

分类学习-评价

- 训练集（training set）：顾名思义用来训练模型的已标注数据，用来建立模型，发现规律
- 测试集（testing set）：也是已标注数据，通常做法是将标注隐藏，输送给训练好的模型，通过结果与真实标注进行对比，评估模型的学习能力

- 训练集/测试集的划分方法：根据已有标注数据集，随机选出一部分（70%）数据作为训练数据，余下的作为测试数据，此外还有交叉验证法，自助法来评估分类模型
- 精确率：精确率是针对我们预估结果而言，（以二分类为例）他表示的是预测为正的样本中有多少是真正的正样本，那么预测为正就有两种可能，一种是把正类预测为正类（TP），另一种就是把负类预测为正类（FP）
- 召回率：是针对我们原有的样本而言，他表示的是样本中的正例有多少被预测正确了，那有两种可能，一种是把原来的正类预测成正类，另一种是把原来的正类预测为负类（FN）

例子

- 假设：我们手上有60个正样本，40个负样本，我们找出所有的正样本，分类算法查找出50个，其中只有40个是真正的正样本，TP：将正类预测为正类数40；FN：将正类预测为负类数20；FP将负类预测为正类数10个；TN将负类预测为负类数为30个
- 准确率（accuracy） = 预测对的 / 所有
  - = （TP + TN） / (TP + FN + FP + TN)
  - = 70 %

### sklearn提供的分类函数主要包括

- K近邻（knn）
- 朴素贝叶斯（naivebayes）
- 支持向量机（svm）
- 决策树（decision tree）
- 神经网络系统（Neural networks）

### 回归分析

- 回归：统计学分析数据的方法，目的在于了解两个或多个变数是否相关，研究其相关方向与强度，并建立数学模型以便于观察特定变数来预测研究者感兴趣的变数。回归分析可以帮助人们了解在自变量变化时，因变量的变化量，一般来说，通过回归分析我们可以由给出自变量估计因变量的条件期望

线性回归函数

- 普通线性回归函数（LinearRegression）
- 岭回归（Ridge）
- Lasso（Lasso）





















